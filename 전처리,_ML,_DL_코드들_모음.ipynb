{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMHQREm/1ns2bIHNDQ2ID+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihun0423/Pipeline-Config/blob/main/%EC%A0%84%EC%B2%98%EB%A6%AC%2C_ML%2C_DL_%EC%BD%94%EB%93%9C%EB%93%A4_%EB%AA%A8%EC%9D%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvU5rLCqZOia"
      },
      "outputs": [],
      "source": [
        "# encoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# machine learning models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "!pip install pycaret\n",
        "from pycaret.regression import *\n",
        "\n",
        "# pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "!pip install skorch\n",
        "\n",
        "from skorch import NeuralNetRegressor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn import set_config\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BAIiVJI9ZeES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3V1uUrkkZeHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3dMvt2loZeJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vaSXDqjxZeMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TmirkU5FZeO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML & DL PIPELINE\n",
        "어느정도 기본적인 전처리 (결측치 제거 & EDA까지 완료한 뒤에 인풋)"
      ],
      "metadata": {
        "id": "6_PtJEqJtget"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(cols, cat_cols, method='lr'):\n",
        "  cat_transformer = OneHotEncoder(sparse_output=False,handle_unknown='ignore')\n",
        "\n",
        "  num_cols = list(set(cols)-set(cat_cols))\n",
        "  num_cols.sort()\n",
        "  num_transformer = RobustScaler()\n",
        "\n",
        "  preprocessor = ColumnTransformer(transformers=[(\"num\",num_transformer,num_cols),\n",
        "                                                 (\"cat\",cat_transformer,cat_cols)])\n",
        "\n",
        "\n",
        "  class FloatTransformer(BaseEstimator, TransformerMixin):\n",
        "      def __init__(self):\n",
        "            pass\n",
        "      def fit(self, X, y=None):\n",
        "            return self\n",
        "      def transform(self, x):\n",
        "            return np.array(x, dtype=np.float32)\n",
        "\n",
        "  if method == 'lr':\n",
        "    ml = LinearRegression(fit_intercept=True)\n",
        "  elif method == 'rf':\n",
        "    ml = RandomForestRegressor()\n",
        "  elif method == 'xgb':\n",
        "    ml = XGBRegressor()\n",
        "  elif method == 'etr':\n",
        "    ml = ExtraTreesRegressor()\n",
        "  elif method == 'torch':\n",
        "    ml = NeuralNetRegressor(Regressor(),max_epochs=100,criterion=nn.MSELoss(),device='cuda:0',optimizer=optim.Adam,optimizer__lr = 0.01)\n",
        "\n",
        "  model = Pipeline(steps=[(\"preprocessor\",preprocessor),\n",
        "                          (\"float64to32\",FloatTransformer()),\n",
        "                          (\"ml\",ml)])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "e3PiMKJnZeRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Regressor(nn.Module):                                                   # 기본적인 MLP\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(nn.Linear(62,30),\n",
        "                               nn.ReLU(),\n",
        "                               nn.Linear(30,30),\n",
        "                               nn.ReLU(),\n",
        "                               nn.Linear(30,10),\n",
        "                               nn.Dropout(0.2),\n",
        "                               nn.ReLU(),\n",
        "                               nn.Linear(10,1),\n",
        "                               )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.model(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "7bw2YZultYi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import set_config\n",
        "set_config(display='diagram')                                                        # pipeline 시각화 설정\n",
        "model = pipeline(list(cols),list(cat_cols), method=\"torch\")                          # pipeline 함수에 모든 컬럼 리스트, 카테고리(범주형)컬럼 리스트, 훈련 할 모델 입력\n",
        "model    # pipeline 확인"
      ],
      "metadata": {
        "id": "D6lDtUm5uDtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline(list(cols),list(cat_cols), method=\"torch\")                          # pipeline 함수에 모든 컬럼 리스트, 카테고리(범주형)컬럼 리스트, 훈련 할 모델 입력\n",
        "model.fit(X_train, y_train.astype(np.float32).values.reshape(-1, 1))                 # method='torch'일 경우에만 np.float32로 변경, 아닐 경우는 y_train으로\n",
        "model"
      ],
      "metadata": {
        "id": "jWoE8fWRZeUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "pp = pipeline(list(cols),list(cat_cols),method='rf')\n",
        "pp"
      ],
      "metadata": {
        "id": "gHLZ-rlIZeW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jmnctduYZeZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EEL8mveTZeb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_1a_0qJZeek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9b_0Pi2gZeg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WgRbQjHHZejm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 데이터 불러오기 (파일 경로를 통해)"
      ],
      "metadata": {
        "id": "pwgcyiEBZgWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요한 패키지들 임포트 및 기본 설정"
      ],
      "metadata": {
        "id": "MFAz-raIwO5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "dJLNYR5xZ6xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "avOzyK7iwTYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    'IMG_SIZE':224,\n",
        "    'EPOCHS':10,\n",
        "    'LEARNING_RATE':3e-4,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}"
      ],
      "metadata": {
        "id": "cRq_JXyxwVAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 프레임에 이미지 경로, 라벨 저장"
      ],
      "metadata": {
        "id": "SbiQIRj_Z7zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/gdrive/MyDrive/open (2)/'\n",
        "train_folder = glob.glob(base_dir + 'train/*')\n",
        "all_img_list = glob.glob(base_dir + 'train/*/*')\n",
        "\n",
        "df = pd.DataFrame(columns=['img_path', 'label'])\n",
        "df['img_path'] = all_img_list            # 이미지 경로 데이터프레임에 저장\n",
        "df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])         # Label명 추출"
      ],
      "metadata": {
        "id": "7BSu3SZRZmAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['label'])   # 라벨 인코딩"
      ],
      "metadata": {
        "id": "KoIeUQznZmDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjdHKWFRZmFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jk5VNmbVxST8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fovf83B7xSXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시각화"
      ],
      "metadata": {
        "id": "3GTcakiGxTKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(data=df, y='label',  palette='crest', dodge=False)\n",
        "plt.show()                     # 라벨 별 분포 확인"
      ],
      "metadata": {
        "id": "os-ZKWDcxWUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,12))\n",
        "for idx, i in enumerate(train_df.label.unique()):\n",
        "    plt.subplot(4, 7, idx+1)\n",
        "\n",
        "    df = train_df[train_df['label'] == i].reset_index(drop = True)\n",
        "    # image_path = df.loc[random.randint(0, len(df))-1, 'path']\n",
        "    image_path = df.loc[random.randint(0, len(df)-1), 'path']\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((224,224))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(i)\n",
        "plt.tight_layout()\n",
        "plt.show()                    # 이미지 일부 확인"
      ],
      "metadata": {
        "id": "Yumz55hMxWWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G1Jy7UP5xWY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TrainTestSplit"
      ],
      "metadata": {
        "id": "gTCop6NAwsug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])"
      ],
      "metadata": {
        "id": "LpAsy7U-wzXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 커스텀 데이터셋 (이미지 경로 활용)"
      ],
      "metadata": {
        "id": "MjM7FRBEaBPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_path_list, label_list, transforms=None):\n",
        "        self.img_path_list = img_path_list\n",
        "        self.label_list = label_list\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_path_list[index]\n",
        "\n",
        "        image = cv2.imread(img_path)                 # PIL로 변환\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(image=image)['image']\n",
        "\n",
        "        if self.label_list is not None:\n",
        "            label = self.label_list[index]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)"
      ],
      "metadata": {
        "id": "JVjuSGWmZmIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
        "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
        "                            ToTensorV2()\n",
        "                            ])                                 # Albumentation패키지를 이용한 augmentation"
      ],
      "metadata": {
        "id": "6reEmIT0uwXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "5EeFcUPDuwZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dATWI6puwcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7Zca3mlVnIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WIP-n_dNVnLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 커스텀 데이터셋(이미 이미지가 로드 되어있을 경우)"
      ],
      "metadata": {
        "id": "9icmNh9jVoML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf = transforms.ToTensor()\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img, label, transforms=None):\n",
        "        self.img = img\n",
        "        self.label = label\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.img[index]\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            image = self.transforms(img)\n",
        "\n",
        "        if self.label is not None:\n",
        "            label = self.label[index]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img)"
      ],
      "metadata": {
        "id": "5mqDWJljVnNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augset=CustomDataset(img=aug_img,label=l.values,transforms=tf)"
      ],
      "metadata": {
        "id": "_jv3SJNFVwNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbLM2DGSV13J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지들의 표준화를 위한 평균, 표준편차 구하기"
      ],
      "metadata": {
        "id": "8JVK7CNRuwrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_stats(dataset):\n",
        "    imgs = np.array([img.numpy() for img, _ in dataset])\n",
        "    print(f'shape: {imgs.shape}')\n",
        "\n",
        "    min_r = np.min(imgs, axis=(2, 3))[:, 0].min()\n",
        "    min_g = np.min(imgs, axis=(2, 3))[:, 1].min()\n",
        "    min_b = np.min(imgs, axis=(2, 3))[:, 2].min()\n",
        "\n",
        "    max_r = np.max(imgs, axis=(2, 3))[:, 0].max()\n",
        "    max_g = np.max(imgs, axis=(2, 3))[:, 1].max()\n",
        "    max_b = np.max(imgs, axis=(2, 3))[:, 2].max()\n",
        "\n",
        "    mean_r = np.mean(imgs, axis=(2, 3))[:, 0].mean()\n",
        "    mean_g = np.mean(imgs, axis=(2, 3))[:, 1].mean()\n",
        "    mean_b = np.mean(imgs, axis=(2, 3))[:, 2].mean()\n",
        "\n",
        "    std_r = np.std(imgs, axis=(2, 3))[:, 0].std()\n",
        "    std_g = np.std(imgs, axis=(2, 3))[:, 1].std()\n",
        "    std_b = np.std(imgs, axis=(2, 3))[:, 2].std()\n",
        "\n",
        "    print(f'min: {min_r, min_g, min_b}')\n",
        "    print(f'max: {max_r, max_g, max_b}')\n",
        "    print(f'mean: {mean_r, mean_g, mean_b}')\n",
        "    print(f'std: {std_r, std_g, std_b}')"
      ],
      "metadata": {
        "id": "Mld3mOd1aH0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((224, 224)),\n",
        "    ])"
      ],
      "metadata": {
        "id": "oyEbyaMIaH21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(df['img_path'].values, df['label'].values, transform)\n",
        "print_stats(train_dataset)"
      ],
      "metadata": {
        "id": "C4WQ63FZaH5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EMXVw3O5u-VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DFApljpBu-Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrjNIxTju-aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yXNP6eHx2dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yjqlTlU6sNdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Q0gkjTksNgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Pm4faTWsNii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (inputs,labels) in enumerate(augmentate_loader):\n",
        "  aug_img = to_pil_image(inputs[0])\n",
        "  aug_img.save('/content/gdrive/MyDrive/open (2)/aug/'+f'{int(labels)}/'+f'{i}.jpg')"
      ],
      "metadata": {
        "id": "R2lglN0OsNk6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}